{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import SimpleITK as sitk\n",
    "import tensorflow as tf\n",
    "from sklearn import feature_extraction\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    img = nib.load(filename)\n",
    "    return img.get_data(), img.affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mri_data,affine = get_data('case_001_2.nii.gz')\n",
    "labelled_data,_ = get_data('tumor.nii.gz')\n",
    "shape = labelled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slice_num = 25\n",
    "slice_size = (24,20)\n",
    "patches = feature_extraction.image.extract_patches_2d(mri_data[:,:,slice_num], slice_size)\n",
    "#patches_output = feature_extraction.image.extract_patches_2d(labelled_data[:,:,slice_num], slice_size)\n",
    "patches_output = labelled_data[12:shape[0]-11,10:shape[1]-9,slice_num]\n",
    "patches_output = np.reshape(patches_output,[patches_output.size,1,1])\n",
    "#patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79765, 24, 20)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model target: expected activation_32 to have shape (None, 24, 1) but got array with shape (79765, 1, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-b70f5cee3702>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m model.compile(optimizer='rmsprop',\n\u001b[0;32m      8\u001b[0m               loss='mse')\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpatches_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    843\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 845\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    846\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m   1403\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1404\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1405\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1406\u001b[0m         \u001b[1;31m# prepare validation data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1407\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[0;32m   1297\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1299\u001b[1;33m                                     exception_prefix='model target')\n\u001b[0m\u001b[0;32m   1300\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[0;32m   1301\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    131\u001b[0m                             \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                             \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m                             str(array.shape))\n\u001b[0m\u001b[0;32m    134\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking model target: expected activation_32 to have shape (None, 24, 1) but got array with shape (79765, 1, 1)"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12,input_shape=slice_size[0]*slice_size[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(3))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('relu'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse')\n",
    "model.fit(patches,patches_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: expected dense_12_input to have 4 dimensions, but got array with shape (79765, 24, 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-28cf3a68ebdc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpatches_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    843\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 845\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    846\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m   1403\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1404\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1405\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1406\u001b[0m         \u001b[1;31m# prepare validation data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1407\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[0;32m   1293\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1295\u001b[1;33m                                     exception_prefix='model input')\n\u001b[0m\u001b[0;32m   1296\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[0;32m   1297\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    119\u001b[0m                                  \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                                  \u001b[1;34m' dimensions, but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m                                  str(array.shape))\n\u001b[0m\u001b[0;32m    122\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking model input: expected dense_12_input to have 4 dimensions, but got array with shape (79765, 24, 20)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79488/79765 [============================>.] - ETA: 0s0.0764743764021\n"
     ]
    }
   ],
   "source": [
    "slice_num2 = 24\n",
    "patches2 = feature_extraction.image.extract_patches_2d(mri_data[:,:,slice_num2], slice_size)\n",
    "patches_output2 = feature_extraction.image.extract_patches_2d(labelled_data[:,:,slice_num2], slice_size)\n",
    "print model.evaluate(patches2,patches_output2)\n",
    "predict = model.predict(patches2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21082.193"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 320)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mri_data[:,:,slice_num].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [ 31.00309695,  21.0229644 ,  15.98669381, ...,  15.98669381,\n",
       "         37.97994887,   0.        ],\n",
       "       [ 32.9898826 ,   4.01977561,  29.98660197, ...,  12.98341318,\n",
       "         18.01968377,   0.        ],\n",
       "       ..., \n",
       "       [  4.99006628,   4.01977561,   3.00328063, ...,  18.98997444,\n",
       "         34.00637758,   0.        ],\n",
       "       [  0.        ,   0.        ,   0.        , ...,  24.99653569,\n",
       "         21.99325506,   0.        ],\n",
       "       [  0.        ,   0.        ,   0.        , ...,   3.00328063,\n",
       "         10.99662753,   0.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mri_data[:,:,slice_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (24,20,3) (24,20) (24,20,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-4d166cdebf7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreconstruct_from_patches_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m288\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m320\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/image.pyc\u001b[0m in \u001b[0;36mreconstruct_from_patches_2d\u001b[1;34m(patches, image_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[0mn_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi_w\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mp_w\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m         \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mp_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mj\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mp_w\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (24,20,3) (24,20) (24,20,3) "
     ]
    }
   ],
   "source": [
    "new_data=feature_extraction.image.reconstruct_from_patches_2d(predict,(288,320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f45c7b15850>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR0AAAEACAYAAACOIqI+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f45c7b9eb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  3],\n",
       "        [12, 15]],\n",
       "\n",
       "       [[ 3,  6],\n",
       "        [15, 18]],\n",
       "\n",
       "       [[ 6,  9],\n",
       "        [18, 21]],\n",
       "\n",
       "       [[12, 15],\n",
       "        [24, 27]],\n",
       "\n",
       "       [[15, 18],\n",
       "        [27, 30]],\n",
       "\n",
       "       [[18, 21],\n",
       "        [30, 33]],\n",
       "\n",
       "       [[24, 27],\n",
       "        [36, 39]],\n",
       "\n",
       "       [[27, 30],\n",
       "        [39, 42]],\n",
       "\n",
       "       [[30, 33],\n",
       "        [42, 45]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=np.array([[ 0,  3,  6,  9],\n",
    "       [12, 15, 18, 21],\n",
    "       [24, 27, 30, 33],\n",
    "       [36, 39, 42, 45]])\n",
    "feature_extraction.image.extract_patches_2d(d, (2, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
