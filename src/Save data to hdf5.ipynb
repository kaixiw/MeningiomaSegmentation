{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get image data w/ nibabel\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "def get_data(filename):\n",
    "    img = nib.load(filename)\n",
    "    return img.get_data()\n",
    "def scale(array):\n",
    "    return (array-np.min(array))/(np.max(array) - np.min(array))    \n",
    "def load(s):\n",
    "    return get_data('../data/case_%s_2.nii.gz'%s).transpose((2,0,1)), get_data('../data/case_%s_labels.nii.gz'%s).transpose((2,0,1))\n",
    "mri_data = scale(get_data('../data/case_002_2.nii.gz')).transpose((2,0,1))\n",
    "labelled_data = get_data('../data/case_002_labels.nii.gz').transpose((2,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a,b = load('001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 9, 5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eh = np.arange(10,1,-1)\n",
    "eh[[3,1,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.misc import imresize\n",
    "def get_data(filename):\n",
    "    img = nib.load(filename)\n",
    "    return img.get_data()\n",
    "def scale(array):\n",
    "    return (array-np.min(array))/(np.max(array) - np.min(array))    \n",
    "def load(s):\n",
    "    return get_data('../data/case_%s_2.nii.gz'%s).transpose((2,0,1)), get_data('../data/case_%s_labels.nii.gz'%s).transpose((2,0,1))\n",
    "def preprocess(mri_slice):\n",
    "    img0 = imresize(mri_slice, (224,224))\n",
    "    img0.resize((img0.shape[0],img0.shape[1],1))\n",
    "    img0 = img0.transpose((2,0,1))\n",
    "    return np.expand_dims(img0, axis=0)\n",
    "def get_testing_data(s):\n",
    "    x, y = load(s)\n",
    "    \n",
    "    x = scale(x)\n",
    "    \n",
    "    x1 = np.zeros((x.shape[0],1,224, 224,))\n",
    "    y1 = np.zeros(x1.shape)\n",
    "    \n",
    "    for n in range(x.shape[0]):\n",
    "        x1[n] = preprocess(x[n])\n",
    "        y1[n] = preprocess(y[n])\n",
    "    return x1, y1\n",
    "def get_training_data(s, slice_filter=\"equal\"):\n",
    "    print(\"Getting data for\",s)\n",
    "    x, y = load(s)\n",
    "    \n",
    "    x_sums_by_slice = x.sum(axis=(1,2)) # used to avoid completely blank slices\n",
    "    y_sums_by_slice = y.sum(axis=(1,2))\n",
    "    \n",
    "    # Get slice #s for slices with/out patches\n",
    "    patch_slices = np.where(y_sums_by_slice>0)[0]\n",
    "    non_patch_slices = np.where((y_sums_by_slice==0) & (x_sums_by_slice>0))[0]\n",
    "    np.random.shuffle(non_patch_slices)\n",
    "        \n",
    "    # Filter\n",
    "    if slice_filter == \"equal\":\n",
    "        #print (non_patch_slices)\n",
    "        non_patch_slices = non_patch_slices[:patch_slices.size]\n",
    "        #print (non_patch_slices)\n",
    "    if slice_filter == \"patches_only\":\n",
    "        non_patch_slices = []\n",
    "    \n",
    "    all_slices = np.concatenate((patch_slices,non_patch_slices)).astype(int)\n",
    "    np.random.shuffle(all_slices)\n",
    "    \n",
    "    \n",
    "    # preprocess data    \n",
    "    x = scale(x)\n",
    "    \n",
    "    x1 = np.zeros((all_slices.size,1,224, 224,))\n",
    "    y1 = np.zeros(x1.shape)\n",
    "    \n",
    "    for n,slice_n in enumerate(all_slices):\n",
    "        x1[n] = preprocess(x[slice_n])\n",
    "        y1[n] = preprocess(y[slice_n])\n",
    "    \n",
    "    return x1, y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17  3  4  5  1  9 20 16 11 13  7  6 12  2  8 31 32 10 15 19 14  0 21 18]\n",
      "[17  3  4  5  1  9 20 16 11]\n",
      "[10 19  9 15 11  2 14 26 16 12  1  4 23  7 25  8  3  5 24 18  0 17 21 13  6]\n",
      "[10 19]\n"
     ]
    }
   ],
   "source": [
    "c,d=get_training_data('001')\n",
    "e,f=get_training_data('002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = np.vstack((c,e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 1, 224, 224)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 1, 224, 224)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/case_021_labels.nii.gz 021\n",
      "../data/case_011_labels.nii.gz 011\n",
      "../data/case_018_labels.nii.gz 018\n",
      "../data/case_047_labels.nii.gz 047\n",
      "../data/case_055_labels.nii.gz 055\n",
      "../data/case_035_labels.nii.gz 035\n",
      "../data/case_007_labels.nii.gz 007\n",
      "../data/case_039_labels.nii.gz 039\n",
      "../data/case_019_labels.nii.gz 019\n",
      "../data/case_008_labels.nii.gz 008\n",
      "../data/case_053_labels.nii.gz 053\n",
      "../data/case_004_labels.nii.gz 004\n",
      "../data/case_058_labels.nii.gz 058\n",
      "../data/case_028_labels.nii.gz 028\n",
      "../data/case_017_labels.nii.gz 017\n",
      "../data/case_010_labels.nii.gz 010\n",
      "../data/case_002_labels.nii.gz 002\n",
      "../data/case_034_labels.nii.gz 034\n",
      "../data/case_014_labels.nii.gz 014\n",
      "../data/case_001_labels.nii.gz 001\n",
      "../data/case_046_labels.nii.gz 046\n",
      "../data/case_009_labels.nii.gz 009\n",
      "../data/case_005_labels.nii.gz 005\n",
      "../data/case_013_labels.nii.gz 013\n",
      "../data/case_052_labels.nii.gz 052\n",
      "../data/case_003_labels.nii.gz 003\n",
      "Training cases:  001, 002, 003, 004, 005, 007, 010, 011, 013, 017, 018, 019, 028, 034, 035, 039, 052, 053, 055, 058\n",
      "Testing cases:  008, 009, 014, 021, 046, 047\n"
     ]
    }
   ],
   "source": [
    "def get_case_num(name):    \n",
    "    return name[name.find(\"case_\")+len(\"case_\"):name.find(\"_labels\")]\n",
    "\n",
    "import glob\n",
    "i = 0\n",
    "\n",
    "all_cases = []\n",
    "for name in glob.glob('../data/*labels.nii.gz'):\n",
    "    i+=1\n",
    "    print(name,get_case_num(name))\n",
    "    all_cases.append(get_case_num(name))\n",
    "    \n",
    "np.random.shuffle(all_cases)\n",
    "\n",
    "# pick 20 training. The rest are \n",
    "train_cases = all_cases[:20]\n",
    "test_cases = all_cases[20:]\n",
    "\n",
    "#train_cases.sort()\n",
    "#test_cases.sort()\n",
    "print (\"Training cases: \",', '.join(sorted(train_cases)))\n",
    "print (\"Testing cases: \",', '.join(sorted(test_cases)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 053\n",
      "Getting data for 052\n",
      "Getting data for 019\n",
      "Getting data for 034\n",
      "Getting data for 035\n",
      "Getting data for 017\n",
      "Getting data for 002\n",
      "Getting data for 058\n",
      "Getting data for 010\n",
      "Getting data for 055\n",
      "Getting data for 039\n",
      "Getting data for 007\n",
      "Getting data for 013\n",
      "Getting data for 028\n",
      "Getting data for 003\n",
      "Getting data for 001\n",
      "Getting data for 005\n",
      "Getting data for 011\n",
      "Getting data for 018\n",
      "Getting data for 004\n"
     ]
    }
   ],
   "source": [
    "train_data,train_labels = get_training_data(train_cases[0],'all')\n",
    "for i in train_cases[1:]:\n",
    "    data, labels = get_training_data(i,'all')\n",
    "    train_data = np.vstack((train_data,data))\n",
    "    train_labels = np.vstack((train_labels,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 047\n",
      "Getting data for 021\n",
      "Getting data for 014\n",
      "Getting data for 008\n",
      "Getting data for 046\n",
      "Getting data for 009\n"
     ]
    }
   ],
   "source": [
    "test_data, test_labels = get_training_data(test_cases[0],'all')\n",
    "for i in test_cases[1:]:\n",
    "    data, labels = get_training_data(i,'all')\n",
    "    test_data = np.vstack((test_data,data))\n",
    "    test_labels = np.vstack((test_labels,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 1, 224, 224)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Shuffle training data\n",
    "p = np.random.permutation(len(train_data))\n",
    "p2 = np.random.permutation(len(test_data))\n",
    "with h5py.File('dataset_1_all.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"train_x\",  data=train_data[p])\n",
    "    hf.create_dataset(\"train_y\",  data=train_labels[p])\n",
    "    hf.create_dataset(\"test_x\",  data=test_data[p2])\n",
    "    hf.create_dataset(\"test_y\",  data=test_labels[p2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
